{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Model: Bayesian Model\n",
    "\n",
    "Steps:\n",
    "1. Edit MPNN model to usd Bayes_Linear and other chemprop layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pprint\n",
    "import yaml\n",
    "from torch import nn\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from matdeeplearn import models, process, training\n",
    "\n",
    "config_path = 'config.yml'\n",
    "#os.path.exists(config_path)\n",
    "# os\n",
    "os.path.abspath(os.getcwd())\n",
    "\n",
    "assert os.path.exists(config_path), (\n",
    "    \"Config file not found in \" + config_path\n",
    "  )\n",
    "with open(config_path, \"r\") as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General imports\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import copy\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import platform\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "##Torch imports\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader, Dataset\n",
    "from torch_geometric.nn import DataParallel\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "##Matdeeplearn imports\n",
    "from matdeeplearn import models\n",
    "import matdeeplearn.process as process\n",
    "import matdeeplearn.training as training\n",
    "from matdeeplearn.models.utils import model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['Job'] = config['Job']['Training']\n",
    "#MEGNet_demo\n",
    "config[\"Models\"] = config[\"Models\"].get(\"CGCNN_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'CGCNN',\n",
       " 'dim1': 100,\n",
       " 'dim2': 150,\n",
       " 'pre_fc_count': 1,\n",
       " 'gc_count': 4,\n",
       " 'post_fc_count': 3,\n",
       " 'pool': 'global_mean_pool',\n",
       " 'pool_order': 'early',\n",
       " 'batch_norm': 'True',\n",
       " 'batch_track_stats': 'True',\n",
       " 'act': 'relu',\n",
       " 'dropout_rate': 0.0,\n",
       " 'epochs': 250,\n",
       " 'lr': 0.002,\n",
       " 'batch_size': 100,\n",
       " 'optimizer': 'AdamW',\n",
       " 'optimizer_args': {},\n",
       " 'scheduler': 'ReduceLROnPlateau',\n",
       " 'scheduler_args': {'mode': 'min',\n",
       "  'factor': 0.8,\n",
       "  'patience': 10,\n",
       "  'min_lr': 1e-05,\n",
       "  'threshold': 0.0002}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"Models\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "config[\"Processing\"][\"data_path\"] = \"data/pt_data/pt_data_2\"\n",
    "world_size = torch.cuda.device_count()\n",
    "print(world_size)\n",
    "rank = 'cuda'\n",
    "print(world_size)\n",
    "data_path = config[\"Processing\"][\"data_path\"]\n",
    "job_parameters= config[\"Job\"]\n",
    "training_parameters= config[\"Training\"]\n",
    "model_parameters= config[\"Models\"]\n",
    "processing_args= config['Processing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Processing\n",
      "train length: 14850 val length: 1980 test length: 2970 unused length: 1 seed : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/varivoda/.local/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "##DDP\n",
    "training.ddp_setup(rank, world_size)\n",
    "##some issues with DDP learning rate\n",
    "if rank not in (\"cpu\", \"cuda\"):\n",
    "    model_parameters[\"lr\"] = model_parameters[\"lr\"] * world_size\n",
    "\n",
    "##Get dataset\n",
    "dataset = process.get_dataset(data_path, training_parameters[\"target_index\"], True,  processing_args= config['Processing'])\n",
    "\n",
    "print('Done Processing')\n",
    "\n",
    "if rank not in (\"cpu\", \"cuda\"):\n",
    "    dist.barrier()\n",
    "\n",
    "##Set up loader\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    train_sampler,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset,\n",
    ") = training.loader_setup(\n",
    "    training_parameters[\"train_ratio\"],\n",
    "    training_parameters[\"val_ratio\"],\n",
    "    training_parameters[\"test_ratio\"],\n",
    "    model_parameters[\"batch_size\"],\n",
    "    dataset,\n",
    "    rank,\n",
    "    job_parameters[\"seed\"],\n",
    "    world_size,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "               Layer.Parameter    Param Tensor Shape              Param #\n",
      "--------------------------------------------------------------------------\n",
      "         pre_lin_list.0.weight            [100, 114]                11400\n",
      "           pre_lin_list.0.bias                 [100]                  100\n",
      "      conv_list.0.lin_f.weight            [100, 250]                25000\n",
      "        conv_list.0.lin_f.bias                 [100]                  100\n",
      "      conv_list.0.lin_s.weight            [100, 250]                25000\n",
      "        conv_list.0.lin_s.bias                 [100]                  100\n",
      "         conv_list.0.bn.weight                 [100]                  100\n",
      "           conv_list.0.bn.bias                 [100]                  100\n",
      "      conv_list.1.lin_f.weight            [100, 250]                25000\n",
      "        conv_list.1.lin_f.bias                 [100]                  100\n",
      "      conv_list.1.lin_s.weight            [100, 250]                25000\n",
      "        conv_list.1.lin_s.bias                 [100]                  100\n",
      "         conv_list.1.bn.weight                 [100]                  100\n",
      "           conv_list.1.bn.bias                 [100]                  100\n",
      "      conv_list.2.lin_f.weight            [100, 250]                25000\n",
      "        conv_list.2.lin_f.bias                 [100]                  100\n",
      "      conv_list.2.lin_s.weight            [100, 250]                25000\n",
      "        conv_list.2.lin_s.bias                 [100]                  100\n",
      "         conv_list.2.bn.weight                 [100]                  100\n",
      "           conv_list.2.bn.bias                 [100]                  100\n",
      "      conv_list.3.lin_f.weight            [100, 250]                25000\n",
      "        conv_list.3.lin_f.bias                 [100]                  100\n",
      "      conv_list.3.lin_s.weight            [100, 250]                25000\n",
      "        conv_list.3.lin_s.bias                 [100]                  100\n",
      "         conv_list.3.bn.weight                 [100]                  100\n",
      "           conv_list.3.bn.bias                 [100]                  100\n",
      "          bn_list.0.lin.weight             [10, 100]                 1000\n",
      "         bn_list.0.norm.weight                [1000]                 1000\n",
      "           bn_list.0.norm.bias                [1000]                 1000\n",
      "          bn_list.1.lin.weight             [10, 100]                 1000\n",
      "         bn_list.1.norm.weight                [1000]                 1000\n",
      "           bn_list.1.norm.bias                [1000]                 1000\n",
      "          bn_list.2.lin.weight             [10, 100]                 1000\n",
      "         bn_list.2.norm.weight                [1000]                 1000\n",
      "           bn_list.2.norm.bias                [1000]                 1000\n",
      "          bn_list.3.lin.weight             [10, 100]                 1000\n",
      "         bn_list.3.norm.weight                [1000]                 1000\n",
      "           bn_list.3.norm.bias                [1000]                 1000\n",
      "        post_lin_list.0.weight            [150, 100]                15000\n",
      "          post_lin_list.0.bias                 [150]                  150\n",
      "        post_lin_list.1.weight            [150, 150]                22500\n",
      "          post_lin_list.1.bias                 [150]                  150\n",
      "        post_lin_list.2.weight            [150, 150]                22500\n",
      "          post_lin_list.2.bias                 [150]                  150\n",
      "                lin_out.weight              [1, 150]                  150\n",
      "                  lin_out.bias                   [1]                    1\n",
      "--------------------------------------------------------------------------\n",
      "Total params: 285701\n",
      "Trainable params: 285701\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "##Set up model\n",
    "model =training.model_setup(\n",
    "    rank,\n",
    "    model_parameters[\"model\"],\n",
    "    model_parameters,\n",
    "    dataset,\n",
    "    job_parameters[\"load_model\"],\n",
    "    job_parameters[\"model_path\"],\n",
    "    model_parameters.get(\"print_model\", True),\n",
    ")\n",
    "\n",
    "##Set-up optimizer & scheduler\n",
    "optimizer = getattr(torch.optim, model_parameters[\"optimizer\"])(\n",
    "    model.parameters(),\n",
    "    lr=model_parameters[\"lr\"],\n",
    "    **model_parameters[\"optimizer_args\"]\n",
    ")\n",
    "scheduler = getattr(torch.optim.lr_scheduler, model_parameters[\"scheduler\"])(\n",
    "    optimizer, **model_parameters[\"scheduler_args\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loss_func = neg_log_like \\nmetric_func = get_metric_func(metric=args.metric)\\nnum_workers = 0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"loss_func = neg_log_like \n",
    "metric_func = get_metric_func(metric=args.metric)\n",
    "num_workers = 0\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CGCNN(\n",
       "  (pre_lin_list): ModuleList(\n",
       "    (0): Linear(in_features=114, out_features=100, bias=True)\n",
       "  )\n",
       "  (conv_list): ModuleList(\n",
       "    (0): CGConv(100, dim=50)\n",
       "    (1): CGConv(100, dim=50)\n",
       "    (2): CGConv(100, dim=50)\n",
       "    (3): CGConv(100, dim=50)\n",
       "  )\n",
       "  (bn_list): ModuleList(\n",
       "    (0): DiffGroupNorm(100, groups=10)\n",
       "    (1): DiffGroupNorm(100, groups=10)\n",
       "    (2): DiffGroupNorm(100, groups=10)\n",
       "    (3): DiffGroupNorm(100, groups=10)\n",
       "  )\n",
       "  (post_lin_list): ModuleList(\n",
       "    (0): Linear(in_features=100, out_features=150, bias=True)\n",
       "    (1): Linear(in_features=150, out_features=150, bias=True)\n",
       "    (2): Linear(in_features=150, out_features=150, bias=True)\n",
       "  )\n",
       "  (lin_out): Linear(in_features=150, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer\n",
      "layer\n",
      "layer\n",
      "layer\n",
      "module\n"
     ]
    }
   ],
   "source": [
    "rho_min_bbp = -5.5\n",
    "rho_max_bbp = -5\n",
    "for module in model.children():\n",
    "    if isinstance(module, torch.nn.modules.container.ModuleList):\n",
    "        for layer in module:\n",
    "            if isinstance(layer,models.mpnn_bayes.BayesLinear):\n",
    "                layer.init_rho(rho_min_bbp, rho_max_bbp)\n",
    "                print(\"layer\")\n",
    "    if isinstance(module,models.mpnn_bayes.BayesLinear):\n",
    "        module.init_rho(rho_min_bbp, rho_max_bbp)\n",
    "        print(\"module\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    mydat = data.to(rank)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__cat_dim__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__inc__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_store',\n",
       " 'apply',\n",
       " 'apply_',\n",
       " 'batch',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'contains_isolated_nodes',\n",
       " 'contains_self_loops',\n",
       " 'contiguous',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'debug',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'edge_attr',\n",
       " 'edge_index',\n",
       " 'edge_stores',\n",
       " 'from_data_list',\n",
       " 'from_dict',\n",
       " 'get',\n",
       " 'has_isolated_nodes',\n",
       " 'has_self_loops',\n",
       " 'index_select',\n",
       " 'is_coalesced',\n",
       " 'is_directed',\n",
       " 'is_undirected',\n",
       " 'keys',\n",
       " 'node_stores',\n",
       " 'num_edge_features',\n",
       " 'num_edges',\n",
       " 'num_faces',\n",
       " 'num_features',\n",
       " 'num_graphs',\n",
       " 'num_node_features',\n",
       " 'num_nodes',\n",
       " 'pin_memory',\n",
       " 'pos',\n",
       " 'record_stream',\n",
       " 'requires_grad_',\n",
       " 'share_memory_',\n",
       " 'size',\n",
       " 'stores',\n",
       " 'stores_as',\n",
       " 'to',\n",
       " 'to_data_list',\n",
       " 'to_dict',\n",
       " 'to_namedtuple',\n",
       " 'x',\n",
       " 'y']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(mydat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, kl = model(mydat, sample = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 100], edge_weight=[100], y=-41.396141052246094, z=[10], u=[1, 3], structure_id=[1], x=[10, 114], edge_attr=[100, 50])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_method = training_parameters['loss']\n",
    "loss_method = 'nll_loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train_dataset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2 or more dimensions (got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-61aa28e3e451>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmydat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2376\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2378\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected 2 or more dimensions (got {})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2 or more dimensions (got 1)"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "data_loss = getattr(F, loss_method)(preds, mydat.y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = data_loss + kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss.retain_grad()\n",
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(119810.6250, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bbp(model, optimizer, loader, loss_method, rank, my_coeff = 1, switch = None, train_size):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    data_loss_sum = 0\n",
    "    kl_loss_sum = 0\n",
    "    kl_loss_depth_sum = 0\n",
    "    count = 0\n",
    "    for data in loader:\n",
    "        data = data.to(rank)\n",
    "        optimizer.zero_grad()\n",
    "        output, kl_loss = model(data, sample=True)\n",
    "        kl_loss /= train_size\n",
    "        data_loss = getattr(F, loss_method)(output, data.y, torch.exp(model.log_noise)) \n",
    "        loss.backward()\n",
    "        loss_all += loss.detach() * output.size(0)\n",
    "        optimizer.step()\n",
    "        count = count + output.size(0)\n",
    "            \n",
    "\n",
    "        # clip = 10\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "        \n",
    "\n",
    "    loss_all = loss_all / count\n",
    "    return loss_all\n",
    "\n",
    "\"\"\"\n",
    "        data_loss_cum = 0\n",
    "        kl_loss_cum = 0\n",
    "\n",
    "        for i in range(args.samples_bbp):\n",
    "            preds, kl_loss_i = model(mol_batch, features_batch, sample=True)\n",
    "            data_loss_i = loss_func(preds, targets, torch.exp(model.log_noise))                    \n",
    "            kl_loss_i /= args.train_data_size                    \n",
    "\n",
    "            data_loss_cum += data_loss_i\n",
    "            kl_loss_cum += kl_loss_i\n",
    "\n",
    "        data_loss = data_loss_cum / args.samples_bbp\n",
    "        kl_loss = kl_loss_cum / args.samples_bbp\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### bbp non sample option\n",
    "\n",
    "#our switch should be 2 and 5 samples\n",
    "if bbp_switch == 1:    \n",
    "    preds, kl_loss = model(mol_batch, features_batch, sample = False)\n",
    "    data_loss = loss_func(preds, targets, torch.exp(model.log_noise))\n",
    "    kl_loss /= args.train_data_size\n",
    "    loss = data_loss + kl_loss  \n",
    "\n",
    "### bbp sample option\n",
    "if bbp_switch == 2:\n",
    "\n",
    "    if args.samples_bbp == 1:\n",
    "        preds, kl_loss = model(mol_batch, features_batch, sample=True)\n",
    "        data_loss = loss_func(preds, targets, torch.exp(model.log_noise))\n",
    "        kl_loss /= args.train_data_size\n",
    "\n",
    "    elif args.samples_bbp > 1:\n",
    "        data_loss_cum = 0\n",
    "        kl_loss_cum = 0\n",
    "\n",
    "        for i in range(args.samples_bbp):\n",
    "            preds, kl_loss_i = model(mol_batch, features_batch, sample=True)\n",
    "            data_loss_i = loss_func(preds, targets, torch.exp(model.log_noise))                    \n",
    "            kl_loss_i /= args.train_data_size                    \n",
    "\n",
    "            data_loss_cum += data_loss_i\n",
    "            kl_loss_cum += kl_loss_i\n",
    "\n",
    "        data_loss = data_loss_cum / args.samples_bbp\n",
    "        kl_loss = kl_loss_cum / args.samples_bbp\n",
    "\n",
    "    loss = data_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from BNNLayer import BNNLayer\n",
    "from BNN import BNN\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader, loss_method, rank, my_coeff = 1):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    count = 0\n",
    "    for data in loader:\n",
    "        data = data.to(rank)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # print(data.y.shape, output.shape)\n",
    "        if loss_method == \"evidential\":\n",
    "            loss =  evidential_regresssion_loss(data.y, output, my_coeff)\n",
    "            loss.backward()\n",
    "            loss_all += loss.detach() * torch.flatten(output[0]).size(0)\n",
    "            optimizer.step()\n",
    "            count = count + torch.flatten(output[0]).size(0)\n",
    "        else:\n",
    "            loss = getattr(F, loss_method)(output, data.y)\n",
    "            loss.backward()\n",
    "            loss_all += loss.detach() * output.size(0)\n",
    "            optimizer.step()\n",
    "            count = count + output.size(0)\n",
    "\n",
    "        # clip = 10\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n",
    "\n",
    "        \n",
    "\n",
    "    loss_all = loss_all / count\n",
    "    return loss_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 114]) torch.Size([100]) torch.Size([100])\n",
      "torch.Size([500, 114]) torch.Size([50]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "        data = data.to(rank)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        print(data.x.shape,data.y.shape, output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    data = data.to(rank)\n",
    "    my_dat = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(my_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 114])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1152, 114])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dat.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Initialize network\n",
    "bnn = BNN(BNNLayer(114, 100, activation='relu', prior_mean=0, prior_rho=0),\n",
    "          BNNLayer(100, 1, activation='none', prior_mean=0, prior_rho=0))\n",
    "\n",
    "optim = torch.optim.Adam(bnn.parameters(), lr=1e-1)\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(50):\n",
    "    for data in train_loader:\n",
    "        kl, lg_lklh = bnn.Forward(data.x, data.y, 5, 'Gaussian')\n",
    "        loss = BNN.loss_fn(kl, lg_lklh, 1)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dat.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-40.6112, -39.0617, -41.3328, -39.4992, -41.4644, -40.3276, -40.2760,\n",
       "        -41.8916, -39.3135, -40.9401, -41.3470, -40.5656, -38.2606, -42.3238,\n",
       "        -41.7147, -39.5980, -42.6903, -39.4735, -36.6092, -42.2160, -39.0374,\n",
       "        -40.2563, -39.9356, -38.0120, -38.9859, -38.8221, -39.0965, -39.5741,\n",
       "        -40.8805, -40.4843, -38.6084, -41.0291, -41.0326, -42.5290, -40.9047,\n",
       "        -40.2822, -41.1662, -40.1886, -41.4339, -39.9165, -41.5909, -40.1056,\n",
       "        -42.6482, -41.4383, -40.8408, -41.6736, -42.4117, -41.1575, -39.8198,\n",
       "        -40.6107, -39.8405, -40.1046, -40.7631, -38.9896, -40.2281, -42.5694,\n",
       "        -42.3701, -40.2304, -39.3464, -40.4437, -40.9188, -41.4603, -42.4589,\n",
       "        -39.7174, -39.6986, -41.3970, -41.3076, -42.7034, -38.1881, -39.5739,\n",
       "        -42.7183, -41.3451, -41.8559, -40.6139, -40.4188, -41.3961, -41.4384,\n",
       "        -39.9930, -41.2173, -38.0770, -41.0816, -38.9201, -41.4408, -39.3002,\n",
       "        -39.0565, -41.5707, -39.9852, -41.2182, -39.2941, -39.0941, -39.8264,\n",
       "        -41.3739, -41.3006, -40.5128, -39.6452, -40.2259, -42.2312, -40.1673,\n",
       "        -40.4019, -42.6009])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data in test_loader:\n",
    "    mydat_2 = data\n",
    "    break\n",
    "mydat_2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lst = [bnn.forward(mydat_2.x, mode='MC').data.numpy().squeeze(1) for _ in range(100)]\n",
    "pred = np.array(pred_lst).T\n",
    "pred_mean = pred.mean(axis=1)\n",
    "pred_std = pred.std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-40.76368 , -40.69465 , -40.65186 , -40.68389 , -40.50751 ,\n",
       "       -40.649426, -40.512314, -40.567337, -40.50829 , -40.854534,\n",
       "       -40.478046, -40.615677, -40.5848  , -40.542377, -40.6007  ,\n",
       "       -40.582447, -40.624035, -40.514698, -40.416447, -40.4691  ,\n",
       "       -40.814247, -40.480526, -40.61916 , -40.576405, -40.765404,\n",
       "       -40.578148, -40.754173, -40.54605 , -40.59684 , -40.960327,\n",
       "       -40.35377 , -40.466003, -40.67522 , -40.68209 , -40.56576 ,\n",
       "       -40.46866 , -40.60142 , -40.38169 , -40.3964  , -40.481373,\n",
       "       -40.521656, -40.51847 , -40.721798, -40.51322 , -40.547752,\n",
       "       -40.479427, -40.741985, -40.649952, -40.6453  , -40.736725,\n",
       "       -40.40797 , -40.815025, -40.425964, -40.48258 , -40.656494,\n",
       "       -40.520332, -40.62672 , -40.741653, -40.436344, -40.78968 ,\n",
       "       -40.605133, -40.745686, -40.486153, -40.436836, -40.658764,\n",
       "       -40.5975  , -40.606346, -40.52455 , -40.55612 , -40.66819 ,\n",
       "       -40.81333 , -40.6959  , -40.478367, -40.492344, -40.474045,\n",
       "       -40.682262, -40.48178 , -40.484314, -40.418488, -40.481583,\n",
       "       -40.255295, -40.621887, -40.60763 , -40.52983 , -40.455414,\n",
       "       -40.812946, -40.549606, -40.503456, -40.632446, -40.72401 ,\n",
       "       -40.652714, -40.327713, -40.75001 , -40.518646, -40.55784 ,\n",
       "       -40.326496, -40.61853 , -40.657764, -40.5434  , -40.416435,\n",
       "       -40.59366 , -40.45878 , -40.75784 , -40.570328, -40.69209 ,\n",
       "       -40.694942, -40.472317, -40.71111 , -40.676186, -40.62075 ,\n",
       "       -40.674652, -40.48341 , -40.465374, -40.853683, -40.55817 ,\n",
       "       -40.52152 , -40.59906 , -40.722675, -40.75302 , -40.68108 ,\n",
       "       -40.609486, -40.6051  , -40.65616 , -40.778473, -40.65716 ,\n",
       "       -40.61803 , -40.436066, -40.738255, -40.799084, -40.895798,\n",
       "       -40.529263, -40.52059 , -40.481735, -40.56316 , -40.47344 ,\n",
       "       -40.75508 , -40.43464 , -40.48809 , -40.68962 , -40.644794,\n",
       "       -40.60397 , -40.466686, -40.56935 , -40.58194 , -40.7706  ,\n",
       "       -40.611916, -40.599922, -40.638206, -40.4472  , -40.64144 ,\n",
       "       -40.538536, -40.793488, -40.815666, -40.467587, -40.47043 ,\n",
       "       -40.65829 , -40.76877 , -40.508087, -40.557926, -40.588142,\n",
       "       -40.43523 , -40.741196, -40.58533 , -40.43602 , -40.38894 ,\n",
       "       -40.65441 , -40.631187, -40.729492, -40.643677, -40.528557,\n",
       "       -40.37816 , -40.53752 , -40.556328, -40.534237, -40.69692 ,\n",
       "       -40.72708 , -40.853207, -40.673435, -40.473827, -40.536938,\n",
       "       -40.56415 , -40.701416, -40.54479 , -40.631035, -40.440147,\n",
       "       -40.62451 , -40.550053, -40.507313, -40.75348 , -40.737095,\n",
       "       -40.706326, -40.824917, -40.63535 , -40.595   , -40.74535 ,\n",
       "       -40.37164 , -40.550533, -40.40313 , -40.656643, -40.720043,\n",
       "       -40.630493, -40.690044, -40.90706 , -40.79311 , -40.664143,\n",
       "       -41.177876, -40.524025, -40.572372, -40.66851 , -40.48883 ,\n",
       "       -40.634144, -40.76472 , -40.77664 , -40.62957 , -40.63815 ,\n",
       "       -40.451164, -40.732098, -40.562897, -40.49673 , -40.68838 ,\n",
       "       -40.456802, -40.475166, -40.677654, -40.530083, -40.6872  ,\n",
       "       -40.581802, -40.484035, -40.355194, -40.4818  , -40.74512 ,\n",
       "       -40.61789 , -40.657665, -40.411945, -40.54896 , -40.89828 ,\n",
       "       -40.751076, -40.77155 , -40.620117, -40.71558 , -40.659706,\n",
       "       -40.527725, -40.37086 , -40.479923, -40.46429 , -40.47478 ,\n",
       "       -40.65645 , -40.54266 , -40.668995, -40.76577 , -40.630882,\n",
       "       -40.694874, -40.397778, -40.45702 , -40.781   , -40.463943,\n",
       "       -40.505722, -40.711727, -40.51974 , -40.576942, -40.436073,\n",
       "       -40.504097, -40.58169 , -40.790493, -40.5988  , -40.664146,\n",
       "       -40.45907 , -40.692413, -40.668705, -40.63498 , -40.583317,\n",
       "       -40.665726, -40.569187, -40.568096, -40.500957, -40.75503 ,\n",
       "       -40.8497  , -40.444744, -40.50862 , -40.64368 , -40.784054,\n",
       "       -40.619125, -40.61352 , -40.643734, -40.62788 , -40.529922,\n",
       "       -40.44903 , -40.670414, -40.741936, -40.6416  , -40.68247 ,\n",
       "       -40.480186, -40.667915, -40.754948, -40.560394, -40.36795 ,\n",
       "       -40.521988, -40.612255, -40.48784 , -40.61611 , -40.29834 ,\n",
       "       -40.607433, -40.589127, -40.62756 , -40.539223, -40.32874 ,\n",
       "       -40.533234, -40.718437, -40.503113, -40.650146, -40.63544 ,\n",
       "       -40.497414, -40.584373, -40.45674 , -40.67415 , -40.59585 ,\n",
       "       -40.397823, -40.5749  , -40.32106 , -40.49331 , -40.67125 ,\n",
       "       -40.710308, -40.408226, -40.606834, -40.669384, -40.56565 ,\n",
       "       -40.56336 , -40.382748, -40.705082, -40.560238, -40.398155,\n",
       "       -40.356976, -40.82635 , -40.461323, -40.666935, -40.583374,\n",
       "       -40.63142 , -40.73731 , -40.63112 , -40.536915, -40.687977,\n",
       "       -40.435993, -40.668488, -40.54181 , -40.57884 , -40.543247,\n",
       "       -40.631577, -40.71364 , -40.59686 , -40.52052 , -40.569523,\n",
       "       -40.29631 , -40.676773, -40.4069  , -40.80928 , -40.35221 ,\n",
       "       -40.519375, -40.587475, -40.606705, -40.753857, -40.61053 ,\n",
       "       -40.65301 , -40.490646, -40.569183, -40.697983, -40.39989 ,\n",
       "       -40.5983  , -40.373905, -40.51509 , -40.713364, -40.67451 ,\n",
       "       -40.595863, -40.70049 , -40.61371 , -40.77305 , -40.549217,\n",
       "       -40.579987, -40.642406, -40.46635 , -40.511642, -40.46623 ,\n",
       "       -40.46376 , -40.469547, -40.80979 , -40.601818, -40.615868,\n",
       "       -40.66896 , -40.648624, -40.592674, -40.723846, -40.809258,\n",
       "       -40.428947, -40.665718, -40.891724, -40.575836, -40.528515,\n",
       "       -40.468597, -40.63068 , -40.82218 , -40.649002, -40.533783,\n",
       "       -40.70774 , -40.66495 , -40.397762, -40.57938 , -40.471466,\n",
       "       -40.64084 , -40.761513, -40.560448, -40.51396 , -40.413147,\n",
       "       -40.478336, -40.47283 , -40.561325, -40.56586 , -40.456398,\n",
       "       -40.54238 , -40.687225, -40.5268  , -40.49884 , -40.838146,\n",
       "       -40.634678, -40.62777 , -40.693653, -40.666832, -40.76084 ,\n",
       "       -40.51276 , -40.373783, -40.58631 , -40.41849 , -40.673485,\n",
       "       -40.63534 , -40.64219 , -40.381126, -40.62823 , -40.72909 ,\n",
       "       -40.518345, -40.432003, -40.876797, -40.474392, -40.544083,\n",
       "       -40.778038, -40.58362 , -40.856243, -40.65431 , -40.60533 ,\n",
       "       -40.54004 , -40.80728 , -40.46562 , -40.529808, -40.65477 ,\n",
       "       -40.543827, -40.716747, -40.85646 , -40.512917, -40.788296,\n",
       "       -40.47247 , -40.56647 , -40.58428 , -40.589405, -40.75858 ,\n",
       "       -40.623924, -40.511593, -40.668938, -40.43249 , -40.53713 ,\n",
       "       -40.589375, -40.586807, -40.610744, -40.551117, -40.71247 ,\n",
       "       -40.587414, -40.5729  , -40.485264, -40.686367, -40.61317 ,\n",
       "       -40.61354 , -40.52272 , -40.633778, -40.628048, -40.675007,\n",
       "       -40.712975, -40.67678 , -40.515392, -40.53812 , -40.630898,\n",
       "       -40.586273, -40.579315, -40.677963, -40.590595, -40.52965 ,\n",
       "       -40.650692, -40.52561 , -40.555603, -40.638493, -40.7106  ,\n",
       "       -40.62864 , -40.563705, -40.454876, -40.583786, -40.647713,\n",
       "       -40.72336 , -40.7002  , -40.725235, -40.618774, -40.555923,\n",
       "       -40.541634, -40.78452 , -40.425804, -40.541553, -40.629513,\n",
       "       -40.537228, -40.55947 , -40.48585 , -40.60832 , -40.530685,\n",
       "       -40.54764 , -40.647663, -40.521595, -40.616158, -40.631145,\n",
       "       -40.500893, -40.606346, -40.564255, -40.477524, -40.506157,\n",
       "       -40.551594, -40.563156, -40.555794, -40.43739 , -40.48278 ,\n",
       "       -40.44855 , -40.378197, -40.61261 , -40.380543, -40.64219 ,\n",
       "       -40.546673, -40.539665, -40.62776 , -40.61033 , -40.45477 ,\n",
       "       -40.500015, -40.448437, -40.7484  , -40.622643, -40.67263 ,\n",
       "       -40.716908, -40.852306, -40.616074, -40.715397, -40.58399 ,\n",
       "       -40.84465 , -40.634586, -40.39895 , -40.56294 , -40.562645,\n",
       "       -40.52848 , -40.48364 , -40.521713, -40.500614, -40.52677 ,\n",
       "       -40.489082, -40.616043, -40.777077, -40.529823, -40.58607 ,\n",
       "       -40.763695, -40.561882, -40.557274, -40.43954 , -40.22945 ,\n",
       "       -40.54999 , -40.741318, -40.475048, -40.57866 , -40.70015 ,\n",
       "       -40.65432 , -40.70301 , -40.482773, -40.51766 , -40.412086,\n",
       "       -40.56762 , -40.5619  , -40.626446, -40.846085, -40.52586 ,\n",
       "       -40.588757, -40.644257, -40.6355  , -40.707405, -40.574047,\n",
       "       -40.642838, -40.813503, -40.605293, -40.59635 , -40.594288,\n",
       "       -40.456543, -40.56328 , -40.53142 , -40.496563, -40.591465,\n",
       "       -40.69304 , -40.644745, -40.470173, -40.54525 , -40.817894,\n",
       "       -40.869907, -40.699043, -40.51889 , -40.444233, -40.622513,\n",
       "       -40.47081 , -40.63081 , -40.544468, -40.37656 , -40.445038,\n",
       "       -40.619797, -40.71516 , -40.537327, -40.304123, -40.52127 ,\n",
       "       -40.578022, -40.65056 , -40.624664, -40.65482 , -40.63565 ,\n",
       "       -40.60991 , -40.539814, -40.67882 , -40.66379 , -40.57844 ,\n",
       "       -40.657383, -40.6307  , -40.59501 , -40.454025, -40.714523,\n",
       "       -40.41138 , -40.62754 , -40.67658 , -40.59745 , -40.56644 ,\n",
       "       -40.566666, -40.583122, -40.531036, -40.442024, -40.44004 ,\n",
       "       -40.437923, -40.491222, -40.492203, -40.55707 , -40.771523,\n",
       "       -40.39287 , -40.72645 , -40.512474, -40.633076, -40.676865,\n",
       "       -40.896786, -40.734596, -40.491814, -40.88571 , -40.454758,\n",
       "       -40.455994, -40.53585 , -40.661415, -40.83406 , -40.592297,\n",
       "       -40.66035 , -40.523483, -40.4892  , -40.462032, -40.603867,\n",
       "       -40.603424, -40.489918, -40.532177, -40.756157, -40.592777,\n",
       "       -40.590546, -40.77366 , -40.504833, -40.51793 , -40.648342,\n",
       "       -40.594513, -40.54157 , -40.51227 , -40.61621 , -40.720753,\n",
       "       -40.70947 , -40.82961 , -40.801132, -40.556065, -40.7023  ,\n",
       "       -40.411175, -40.485043, -40.5753  , -40.552174, -40.6751  ,\n",
       "       -40.54378 , -40.443672, -40.60932 , -40.667263, -40.642612,\n",
       "       -40.515495, -40.58458 , -40.76093 , -40.727905, -40.676033,\n",
       "       -40.587643, -40.45104 , -40.644493, -40.697357, -40.615284,\n",
       "       -40.570114, -40.628487, -40.688267, -40.46283 , -40.623234,\n",
       "       -40.48778 , -40.48461 , -40.6082  , -40.43352 , -40.578938,\n",
       "       -40.67877 , -40.743725, -40.59129 , -40.655785, -40.52747 ,\n",
       "       -40.528614, -40.761593, -40.528015, -40.5255  , -40.586784,\n",
       "       -40.636368, -40.604485, -40.567917, -40.598503, -40.651573,\n",
       "       -40.412792, -40.644268, -40.53245 , -40.677994, -40.43593 ,\n",
       "       -40.429047, -40.69109 , -40.702053, -40.729618, -40.679897,\n",
       "       -40.64002 , -40.53192 , -40.63823 , -40.549774, -40.454266,\n",
       "       -40.58621 , -40.355297, -40.750957, -40.529236, -40.64212 ,\n",
       "       -40.495888, -40.78474 , -40.666344, -40.54983 , -40.63045 ,\n",
       "       -40.398705, -40.35978 , -40.79022 , -40.593163, -40.648705,\n",
       "       -40.445747, -40.46993 , -40.792374, -40.432823, -40.46666 ,\n",
       "       -40.76231 , -40.548817, -40.475994, -40.69815 , -40.45698 ,\n",
       "       -40.507954, -40.59665 , -40.58322 , -40.494495, -40.68745 ,\n",
       "       -40.64403 , -40.50276 , -40.648254, -40.758198, -40.47667 ,\n",
       "       -40.60176 , -40.456593, -40.622562, -40.68321 , -40.666775,\n",
       "       -40.523987, -40.665554, -40.642624, -40.525543, -40.597202,\n",
       "       -40.6583  , -40.709835, -40.532993, -40.63309 , -40.67517 ,\n",
       "       -40.49359 , -40.51843 , -40.594143, -40.52075 , -40.906433,\n",
       "       -40.388508, -40.808277, -40.63358 , -40.549156, -40.511887,\n",
       "       -40.549038, -40.626503, -40.65663 , -40.569695, -40.575138,\n",
       "       -40.67875 , -40.530663, -40.703148, -40.422577, -40.50244 ,\n",
       "       -40.570793, -40.753536, -40.568375, -40.49666 , -40.53514 ,\n",
       "       -40.61991 , -40.64766 , -40.424488, -40.597225, -40.576775,\n",
       "       -40.779694, -40.55384 , -40.749153, -40.653614, -40.625935,\n",
       "       -40.66782 , -40.724808, -40.560585, -40.544395, -40.455563,\n",
       "       -40.646835, -40.634518, -40.844585, -40.78215 , -40.545254,\n",
       "       -40.49079 , -40.87442 , -40.69936 , -40.567883, -40.54136 ,\n",
       "       -40.634464, -40.63847 , -40.535652, -40.58486 , -40.617558,\n",
       "       -40.648666, -40.65417 , -40.56339 , -40.523705, -40.716263,\n",
       "       -40.51528 , -40.571915, -40.77881 , -40.7796  , -40.735615,\n",
       "       -40.42396 , -40.72731 , -40.661972, -40.600895, -40.72755 ,\n",
       "       -40.526764, -40.628605, -40.567413, -40.645943, -40.578224,\n",
       "       -40.616894, -40.62747 , -40.48448 , -40.647373, -40.73219 ,\n",
       "       -40.555023, -40.666656, -40.621662, -40.571693, -40.655567,\n",
       "       -40.67002 , -40.52773 , -40.66507 , -40.609364, -40.649933,\n",
       "       -40.570362, -40.694252, -40.77562 , -40.391712, -40.50288 ,\n",
       "       -40.45802 , -40.618317, -40.399532, -40.704205, -40.529625,\n",
       "       -40.731693, -40.601395, -40.688587, -40.36039 , -40.75431 ,\n",
       "       -40.55156 , -40.51    , -40.714455, -40.62483 , -40.704662,\n",
       "       -40.496243, -40.845642, -40.707443, -40.651417, -40.47512 ,\n",
       "       -40.513004, -40.51716 , -40.633987, -40.76222 , -40.697983,\n",
       "       -40.81885 , -40.435883, -40.581177, -40.514896, -40.578075,\n",
       "       -40.624386, -40.58752 , -40.63435 , -40.73449 , -40.547268,\n",
       "       -40.699635, -40.69931 , -40.619152, -40.43277 , -40.517155,\n",
       "       -40.736916, -40.38948 , -40.49352 , -40.4254  , -40.744415,\n",
       "       -40.508423, -40.53539 , -40.592472, -40.69053 , -40.63121 ,\n",
       "       -40.524742, -40.607555, -40.516445, -40.740894, -40.82704 ,\n",
       "       -40.33361 , -40.603878, -40.657352, -40.545425, -40.56749 ,\n",
       "       -40.695114, -40.635635, -40.80697 , -40.490414, -40.54315 ,\n",
       "       -40.45803 , -40.71885 , -40.680374, -40.57488 , -40.473675,\n",
       "       -40.639576, -40.428898, -40.597572, -40.422962, -40.562153,\n",
       "       -40.679947, -40.591522, -40.670063, -40.545795, -40.60592 ,\n",
       "       -40.670956, -40.656017, -40.4998  , -40.654232, -40.611843,\n",
       "       -40.62779 , -40.460526, -40.5082  , -40.70464 , -40.644897,\n",
       "       -40.456455, -40.549713, -40.445217, -40.56099 , -40.556957,\n",
       "       -40.79371 , -40.541656, -40.574886, -40.66746 , -40.71537 ,\n",
       "       -40.750954, -40.5345  , -40.810585, -40.414337, -40.68663 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0547813 , 1.2954718 , 1.1567339 , 1.1680073 , 1.1681857 ,\n",
       "       1.0926514 , 1.2417028 , 1.2096938 , 1.0787663 , 1.208754  ,\n",
       "       1.0554477 , 1.2546116 , 1.0570738 , 1.0812312 , 1.3572689 ,\n",
       "       1.1870748 , 1.09098   , 1.3453679 , 0.96389604, 1.3075686 ,\n",
       "       1.1034024 , 1.1449726 , 1.0919079 , 1.0964007 , 1.2822737 ,\n",
       "       1.1204354 , 1.3033876 , 1.178195  , 1.0792165 , 1.1797916 ,\n",
       "       1.2000948 , 1.2065288 , 1.1125236 , 1.1267766 , 1.2139312 ,\n",
       "       1.1807195 , 1.2163414 , 1.14374   , 1.0159215 , 1.123853  ,\n",
       "       1.0892687 , 1.1751349 , 1.2055798 , 1.2320247 , 1.0799826 ,\n",
       "       1.1605153 , 1.2267975 , 1.1553559 , 1.2382569 , 1.2924211 ,\n",
       "       1.1440053 , 1.1851903 , 1.2156494 , 1.0019516 , 1.166209  ,\n",
       "       1.2151327 , 1.0975863 , 1.1164252 , 1.0995458 , 1.1612872 ,\n",
       "       1.1375529 , 1.1420051 , 1.3190334 , 1.3501195 , 1.2169507 ,\n",
       "       1.0831354 , 1.2276876 , 1.2129567 , 1.01441   , 1.1461436 ,\n",
       "       1.0903529 , 1.223599  , 1.1849741 , 1.3343154 , 1.0736398 ,\n",
       "       1.1806756 , 1.1935465 , 1.1861806 , 1.0809579 , 1.1336683 ,\n",
       "       1.1363088 , 1.142716  , 1.1985947 , 1.2249708 , 1.0964414 ,\n",
       "       1.1807195 , 1.1750311 , 1.1436645 , 1.1844556 , 1.218231  ,\n",
       "       1.3079106 , 1.2753668 , 1.2233745 , 1.1441455 , 1.1411817 ,\n",
       "       1.2762427 , 1.2091771 , 1.1188029 , 1.1281669 , 1.4292994 ,\n",
       "       1.2157571 , 1.1623842 , 1.166913  , 1.3125107 , 1.0414437 ,\n",
       "       1.1552839 , 0.97873896, 1.1706363 , 1.1532557 , 1.1241996 ,\n",
       "       1.2069522 , 1.2255396 , 1.1166404 , 1.1140364 , 1.1642934 ,\n",
       "       1.2077239 , 1.2258017 , 1.2585073 , 1.0643523 , 1.0915048 ,\n",
       "       0.9835981 , 1.3221908 , 1.1062183 , 1.239636  , 1.1165531 ,\n",
       "       1.2201366 , 1.2733247 , 1.1217703 , 1.2140101 , 1.2416135 ,\n",
       "       1.2655954 , 1.2540927 , 1.1115282 , 1.1755099 , 1.1499851 ,\n",
       "       1.1248689 , 1.1452293 , 1.2988786 , 1.1479608 , 1.16235   ,\n",
       "       1.2437526 , 1.1651375 , 1.1484827 , 1.1078953 , 1.2109317 ,\n",
       "       1.0758243 , 1.0547704 , 1.1909871 , 1.2559384 , 1.1484427 ,\n",
       "       1.0712843 , 1.038519  , 1.3567455 , 1.2189118 , 1.254782  ,\n",
       "       1.2479755 , 1.2253445 , 1.2151984 , 1.1127466 , 1.09298   ,\n",
       "       1.2713337 , 1.1849436 , 1.1918423 , 1.096385  , 1.2312044 ,\n",
       "       1.1517546 , 1.2041363 , 1.2870499 , 1.0664734 , 1.2593353 ,\n",
       "       1.2356917 , 1.246812  , 1.1863322 , 1.1469144 , 1.2212162 ,\n",
       "       1.2631121 , 1.2645707 , 1.1949593 , 1.301652  , 1.3097212 ,\n",
       "       1.0143409 , 1.1743093 , 1.1973805 , 1.0231296 , 1.1506534 ,\n",
       "       1.137496  , 1.096634  , 1.2258252 , 1.0918415 , 1.1259162 ,\n",
       "       1.1040925 , 1.058969  , 1.2477108 , 1.0451751 , 1.234493  ,\n",
       "       1.0345845 , 1.0258963 , 1.034352  , 1.0770158 , 1.230709  ,\n",
       "       1.3032963 , 1.0963559 , 1.2348995 , 1.3158381 , 1.292288  ,\n",
       "       1.4846163 , 1.1288276 , 1.2052113 , 1.0485933 , 1.0689926 ,\n",
       "       0.9792463 , 1.1905552 , 1.1366911 , 1.2473403 , 1.1591483 ,\n",
       "       1.147148  , 1.0982105 , 1.228113  , 1.1707202 , 1.327294  ,\n",
       "       1.205664  , 1.1186165 , 1.2223418 , 1.0861712 , 1.1842492 ,\n",
       "       1.2164447 , 1.1456916 , 1.1687359 , 0.9173008 , 1.1078542 ,\n",
       "       1.1715708 , 1.2579522 , 1.068908  , 1.2568501 , 1.3328751 ,\n",
       "       1.22847   , 1.1303545 , 1.1786592 , 1.1553333 , 1.1236297 ,\n",
       "       1.189841  , 1.0918076 , 1.2151027 , 1.0160064 , 0.9966801 ,\n",
       "       1.1879077 , 1.0414304 , 1.1265647 , 1.0986685 , 1.1969345 ,\n",
       "       1.3549978 , 1.2424849 , 1.0662035 , 1.1579    , 1.0659086 ,\n",
       "       1.1236124 , 1.1001021 , 1.1710733 , 1.2610008 , 1.200621  ,\n",
       "       1.1750832 , 1.2594279 , 1.2455165 , 1.1890633 , 1.1283929 ,\n",
       "       1.2617153 , 1.1511493 , 1.1099159 , 1.2217803 , 1.1296813 ,\n",
       "       1.0874822 , 1.2828099 , 1.1700557 , 1.3140734 , 1.0866002 ,\n",
       "       1.0476227 , 1.1551367 , 1.0358186 , 1.1809533 , 1.0896988 ,\n",
       "       1.3409218 , 1.1637312 , 1.3304557 , 1.1340859 , 1.1692358 ,\n",
       "       1.039736  , 0.98838294, 1.1742237 , 1.2173861 , 1.1598426 ,\n",
       "       1.0958283 , 1.0561732 , 1.1584781 , 1.2045138 , 1.2677324 ,\n",
       "       1.1130126 , 1.1721107 , 1.0811564 , 1.1164913 , 1.086282  ,\n",
       "       1.1353698 , 1.0191518 , 1.2340978 , 1.216712  , 1.0445765 ,\n",
       "       1.1488853 , 1.2692803 , 1.2185818 , 1.0879011 , 1.246998  ,\n",
       "       1.3426032 , 1.1091782 , 1.1692808 , 1.0635424 , 1.1385567 ,\n",
       "       1.3150582 , 0.99038076, 1.1565193 , 1.1509714 , 1.288149  ,\n",
       "       1.0795016 , 1.2522143 , 1.2561387 , 1.1895849 , 1.2328103 ,\n",
       "       1.1396782 , 1.1409601 , 1.2637922 , 1.0855476 , 1.2011396 ,\n",
       "       1.0806376 , 1.2274427 , 1.0907322 , 1.10771   , 1.064252  ,\n",
       "       1.1737132 , 1.1800661 , 1.1803489 , 1.1159395 , 1.0913771 ,\n",
       "       1.2596016 , 1.2573763 , 1.0666336 , 1.2182055 , 1.0567721 ,\n",
       "       1.2002182 , 1.2780685 , 1.0551926 , 1.2489237 , 1.2124567 ,\n",
       "       1.2191498 , 1.1570792 , 1.283178  , 1.1801503 , 1.1541805 ,\n",
       "       1.1902363 , 1.2894297 , 1.0986708 , 1.0696741 , 1.2441274 ,\n",
       "       1.2484121 , 1.0549879 , 1.1454997 , 1.238301  , 1.1989897 ,\n",
       "       1.2176994 , 1.0999047 , 1.0403521 , 1.2107128 , 1.0195405 ,\n",
       "       1.2446338 , 1.281624  , 1.1893594 , 1.1985563 , 1.1009734 ,\n",
       "       1.0495169 , 1.1771067 , 1.0812504 , 1.2009706 , 1.2062439 ,\n",
       "       1.2514085 , 1.1467322 , 1.2073166 , 1.1462077 , 1.009233  ,\n",
       "       1.1513973 , 1.2499526 , 1.1957519 , 1.1529317 , 1.1674265 ,\n",
       "       1.1295938 , 1.0720975 , 1.3095251 , 1.1873174 , 1.2083633 ,\n",
       "       1.2244215 , 1.0400125 , 1.1961124 , 1.2052176 , 1.2178365 ,\n",
       "       1.1278458 , 1.2294585 , 1.2710971 , 1.221713  , 1.0402157 ,\n",
       "       1.3274498 , 1.2090976 , 1.2381222 , 1.2289335 , 1.257346  ,\n",
       "       1.1781285 , 1.122247  , 1.1327631 , 1.2865635 , 1.2918798 ,\n",
       "       1.0703046 , 1.2329413 , 1.1138233 , 1.0689273 , 1.217128  ,\n",
       "       1.007767  , 1.2206272 , 1.1347356 , 1.1977416 , 1.2335656 ,\n",
       "       1.1341108 , 1.0044008 , 1.1978995 , 1.1369565 , 1.0913371 ,\n",
       "       1.1511981 , 1.1706716 , 1.2499673 , 1.0257905 , 1.2615852 ,\n",
       "       1.2329838 , 1.2338078 , 1.0990678 , 1.2604239 , 1.1398411 ,\n",
       "       1.0693971 , 1.2231736 , 1.1150095 , 1.0795232 , 1.033198  ,\n",
       "       1.0885851 , 1.1849892 , 1.3002046 , 1.2008061 , 1.0790951 ,\n",
       "       1.257983  , 1.2373657 , 1.0819986 , 1.1482987 , 1.0514348 ,\n",
       "       1.1554542 , 1.3437448 , 1.326253  , 1.2221162 , 0.9807542 ,\n",
       "       1.3622046 , 1.1295905 , 1.1626221 , 1.0965459 , 1.2185738 ,\n",
       "       1.198295  , 1.1168582 , 1.1259816 , 1.142713  , 1.1738374 ,\n",
       "       1.1816623 , 1.2159921 , 1.1017209 , 1.2197597 , 1.2393953 ,\n",
       "       1.2162557 , 1.1691568 , 1.096276  , 1.2467667 , 1.2391096 ,\n",
       "       1.2018661 , 1.1141075 , 1.204293  , 1.2067015 , 1.095539  ,\n",
       "       1.1901991 , 1.200862  , 1.2745434 , 1.0333884 , 1.1760356 ,\n",
       "       1.135746  , 1.2713718 , 1.2012142 , 1.1307305 , 1.2150549 ,\n",
       "       1.1070198 , 1.3491741 , 1.2479553 , 1.0725753 , 1.1804656 ,\n",
       "       1.1659607 , 1.2808797 , 1.1097327 , 1.2964374 , 1.3143054 ,\n",
       "       1.1154608 , 1.1466671 , 1.1739973 , 1.2345189 , 1.1318405 ,\n",
       "       1.1907662 , 1.1365888 , 1.3474716 , 1.1050496 , 1.2373986 ,\n",
       "       1.2548229 , 1.2081947 , 1.150363  , 1.2604263 , 1.1254203 ,\n",
       "       1.1055596 , 1.2236539 , 1.0926186 , 1.0549864 , 1.1942632 ,\n",
       "       1.1574494 , 0.9933959 , 1.0858835 , 1.0565541 , 1.2783861 ,\n",
       "       1.2053548 , 1.2149298 , 1.0665274 , 1.1297448 , 1.2443143 ,\n",
       "       1.1115862 , 1.258961  , 1.09654   , 1.1297604 , 1.1603676 ,\n",
       "       1.126909  , 1.1704226 , 1.1770114 , 1.1971698 , 1.243055  ,\n",
       "       1.162116  , 1.0911897 , 1.1776881 , 1.3680555 , 1.300582  ,\n",
       "       1.2281393 , 1.0760328 , 1.2980176 , 1.3463211 , 1.1410234 ,\n",
       "       1.2549311 , 1.1068432 , 1.1864349 , 1.0709833 , 1.1838187 ,\n",
       "       1.2258825 , 1.164338  , 1.0533676 , 1.1657653 , 1.0679082 ,\n",
       "       1.1064352 , 1.2129757 , 1.2282096 , 1.0884967 , 1.1581447 ,\n",
       "       1.1124474 , 1.3384116 , 1.2588272 , 0.99711645, 1.1297122 ,\n",
       "       1.286692  , 1.2488197 , 1.2734978 , 1.1640154 , 1.1279871 ,\n",
       "       1.2506037 , 1.1151179 , 1.0768012 , 1.2133687 , 1.2457129 ,\n",
       "       1.2827543 , 1.2508126 , 1.2334906 , 1.2193867 , 1.2109382 ,\n",
       "       1.2505832 , 1.2756133 , 1.4162047 , 1.2268186 , 1.0755465 ,\n",
       "       1.2147651 , 1.3251041 , 1.2533423 , 1.2131499 , 1.2321907 ,\n",
       "       1.2502939 , 1.1767325 , 1.1894414 , 1.1825132 , 1.0720154 ,\n",
       "       1.1214031 , 1.0988169 , 1.2195367 , 1.1056256 , 1.1870235 ,\n",
       "       1.2120876 , 1.1239829 , 1.2476776 , 1.0938118 , 1.0660859 ,\n",
       "       1.0487454 , 1.1333361 , 1.1540914 , 1.1678295 , 1.1349841 ,\n",
       "       1.2129126 , 1.0950092 , 1.098346  , 1.1219578 , 1.1403027 ,\n",
       "       1.102624  , 1.1024351 , 1.1542902 , 1.1061741 , 1.3284075 ,\n",
       "       1.1101326 , 1.2188073 , 1.1655302 , 1.0305889 , 1.041537  ,\n",
       "       1.0932752 , 1.1854433 , 1.3861456 , 1.2808361 , 1.135275  ,\n",
       "       1.3638352 , 1.3192798 , 1.1514806 , 1.2479718 , 1.1907309 ,\n",
       "       1.175371  , 1.1201576 , 1.1102211 , 1.1835067 , 1.2587456 ,\n",
       "       1.0320839 , 1.3170383 , 1.2077981 , 1.2835788 , 1.1630398 ,\n",
       "       1.088399  , 1.130232  , 1.2712922 , 1.2429609 , 1.1074284 ,\n",
       "       1.1927185 , 1.1622179 , 1.2332976 , 1.2152348 , 1.0586673 ,\n",
       "       1.1217645 , 1.212191  , 1.1463873 , 1.0138447 , 1.1562507 ,\n",
       "       1.2356993 , 1.2550273 , 1.1154389 , 1.2503908 , 1.0524703 ,\n",
       "       1.1821675 , 1.1605769 , 1.1614945 , 1.2164522 , 1.1558963 ,\n",
       "       1.114363  , 1.1615926 , 1.0295873 , 1.2292398 , 1.2436002 ,\n",
       "       1.2738609 , 1.2565806 , 1.1365374 , 1.2936568 , 1.098021  ,\n",
       "       1.2215546 , 1.1813707 , 1.1745092 , 1.2157924 , 1.1668437 ,\n",
       "       1.0941925 , 1.1900597 , 1.180993  , 1.0271578 , 1.1091379 ,\n",
       "       1.1818277 , 1.2243655 , 1.1640849 , 1.1580163 , 1.2952839 ,\n",
       "       1.1584823 , 1.209692  , 1.123704  , 1.0547931 , 1.0432619 ,\n",
       "       1.1528002 , 1.1211828 , 1.1384084 , 1.0978695 , 1.1276301 ,\n",
       "       1.1474793 , 1.239758  , 0.96861535, 1.2242228 , 1.0782173 ,\n",
       "       1.1638336 , 1.2548094 , 1.0086102 , 1.3089156 , 1.1225597 ,\n",
       "       1.1400465 , 1.2150126 , 1.220121  , 1.2129519 , 1.070109  ,\n",
       "       1.1354542 , 1.0898948 , 1.0991684 , 1.1346939 , 1.1215985 ,\n",
       "       1.0323489 , 1.1612241 , 1.0475181 , 1.026254  , 1.2427622 ,\n",
       "       1.2286273 , 1.179873  , 1.1587211 , 1.1290561 , 1.1176621 ,\n",
       "       1.1639792 , 1.2485461 , 1.2876449 , 1.063894  , 1.0901879 ,\n",
       "       1.1880347 , 1.1403896 , 1.2325219 , 1.2666651 , 1.0295248 ,\n",
       "       1.1654159 , 1.0281748 , 1.0611854 , 1.1826837 , 1.2569519 ,\n",
       "       1.1174519 , 1.2305655 , 1.2656515 , 1.3023694 , 1.2088543 ,\n",
       "       1.143502  , 1.180273  , 1.1430593 , 1.1497265 , 1.1959685 ,\n",
       "       1.3292254 , 1.1918336 , 1.1270175 , 1.2108929 , 1.1768639 ,\n",
       "       1.2180164 , 1.3015497 , 1.3660867 , 1.053276  , 1.1225153 ,\n",
       "       1.2072372 , 1.100711  , 1.18817   , 1.2308068 , 1.2205616 ,\n",
       "       1.1903266 , 1.0718696 , 1.1358743 , 1.1536893 , 1.175122  ,\n",
       "       1.1867406 , 1.1046757 , 0.9988496 , 1.1449677 , 1.2890704 ,\n",
       "       1.0399468 , 1.0945266 , 1.0134089 , 1.20789   , 1.2060634 ,\n",
       "       1.2570751 , 1.0573123 , 1.2590657 , 1.1808095 , 1.1680974 ,\n",
       "       1.2405566 , 1.1152735 , 1.3348814 , 1.2189736 , 1.1324344 ,\n",
       "       1.2027236 , 1.1565812 , 1.1558543 , 1.1183343 , 1.1511402 ,\n",
       "       1.250318  , 1.1473738 , 1.1690687 , 1.0249995 , 1.2977656 ,\n",
       "       1.1285995 , 1.2073894 , 1.0691631 , 1.1304204 , 1.1596699 ,\n",
       "       1.2987376 , 1.0746146 , 1.080347  , 1.1588379 , 1.2547576 ,\n",
       "       1.1059031 , 1.1787491 , 1.1244216 , 1.16682   , 1.0692072 ,\n",
       "       1.1841989 , 1.0672437 , 1.2687337 , 1.0966523 , 1.1031741 ,\n",
       "       1.1355528 , 1.1082302 , 1.2348667 , 1.1490024 , 1.0291929 ,\n",
       "       1.1516153 , 1.2080072 , 1.13742   , 1.175827  , 1.1203982 ,\n",
       "       1.1234598 , 1.2015826 , 1.1814704 , 1.2248076 , 1.0651178 ,\n",
       "       1.1283854 , 1.1096082 , 1.1817759 , 1.1798542 , 1.0485399 ,\n",
       "       1.1110896 , 1.1305965 , 0.990856  , 1.1268289 , 1.2030073 ,\n",
       "       1.2022153 , 1.2056806 , 1.2699858 , 1.2016793 , 1.2387375 ,\n",
       "       1.0631833 , 1.2083737 , 1.2576648 , 1.1588722 , 1.1452432 ,\n",
       "       1.1549898 , 1.1042045 , 1.1849524 , 1.0890158 , 1.0953528 ,\n",
       "       1.2435396 , 1.1129953 , 1.0997189 , 1.2768888 , 1.2870921 ,\n",
       "       1.326764  , 1.2555312 , 1.1740212 , 1.3082585 , 1.0654892 ,\n",
       "       1.0968217 , 1.1311057 , 1.1965643 , 1.0205363 , 1.0398647 ,\n",
       "       1.1584604 , 1.1718618 , 1.3146169 , 1.2448087 , 1.2174729 ,\n",
       "       1.1571655 , 1.1015872 , 1.2488769 , 1.1646075 , 1.1064318 ,\n",
       "       1.2303613 , 1.2707037 , 1.1681646 , 1.366564  , 1.1399227 ,\n",
       "       1.1223943 , 1.0850737 , 1.0716473 , 1.2304825 , 1.0849204 ,\n",
       "       1.107782  , 1.0939422 , 1.349518  , 1.1545529 , 1.2791529 ,\n",
       "       1.1018971 , 1.2629375 , 1.3345251 , 1.2621983 , 1.0891973 ,\n",
       "       1.1104993 , 1.0206137 , 1.2418208 , 1.1813235 , 1.2169098 ,\n",
       "       1.1470143 , 1.066464  , 1.1193136 , 1.188588  , 1.2139289 ,\n",
       "       1.159633  , 1.1328827 , 1.2239074 , 1.1391281 , 1.057891  ,\n",
       "       1.0827742 , 1.171703  , 1.2516993 , 1.1553987 , 1.0755088 ,\n",
       "       1.2200722 , 1.2970448 , 1.1338602 , 1.1623813 , 1.112021  ,\n",
       "       1.3495791 , 1.0353165 , 1.1536728 , 1.1698706 , 1.1457398 ,\n",
       "       1.1808774 , 1.1887721 , 1.0658177 , 1.2128274 , 1.1170936 ,\n",
       "       1.2748735 , 1.1798466 , 1.1023151 , 1.1312467 , 1.094407  ,\n",
       "       1.2261375 , 1.1154457 , 0.9613853 , 1.2578444 , 1.208199  ,\n",
       "       1.1149616 , 1.179161  , 1.1342881 , 1.2090062 , 1.1333107 ,\n",
       "       1.317398  , 1.2632686 , 1.240788  , 1.1084344 , 1.1842897 ,\n",
       "       1.2804395 , 1.2386743 , 1.1953712 , 1.2876095 , 1.2195128 ,\n",
       "       1.2360872 , 1.1097146 , 1.2264091 , 1.1010044 , 1.1951125 ,\n",
       "       1.150881  , 1.1416618 , 1.2511485 , 1.2465894 , 1.1117855 ,\n",
       "       1.1342942 , 1.1979498 , 1.4047781 , 1.1719627 , 1.0684639 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = Variable(test_set.test_data.view(test_size, -1).type(torch.FloatTensor))\n",
    "test_Y = Variable(test_set.test_labels.view(test_size, -1))\n",
    "\n",
    "pred_class = bnn.forward(test_X, mode='MAP').data.numpy().argmax(axis=1)\n",
    "true_class = test_Y.data.numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-b490da374ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'navy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.scatter(x, y, c='navy', label='target')\n",
    "\n",
    "x_ = np.linspace(-5, 5)\n",
    "y_ = x_ ** 3\n",
    "X_ = Var(x_).unsqueeze(1)\n",
    "\n",
    "pred_lst = [bnn.forward(X_, mode='MC').data.numpy().squeeze(1) for _ in range(100)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 114])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dat.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mean.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydat_2.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(pred_lst).T\n",
    "pred_mean = pred.mean(axis=1)\n",
    "pred_std = pred.std(axis=1)\n",
    "\n",
    "\n",
    "plt.plot(mydat_2.x, pred_mean, c='royalblue', label='mean pred')\n",
    "plt.fill_between(mydat_2.x, pred_mean - 3 * pred_std, pred_mean + 3 * pred_std,\n",
    "                 color='cornflowerblue', alpha=.5, label='+/- 3 std')\n",
    "\n",
    "plt.plot(mydat_2.x, mydat_2.y, c='grey', label='truth')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "loss_all = 0\n",
    "count = 0\n",
    "for data in test_loader:\n",
    "    data = data.to(rank)\n",
    "    with torch.no_grad():\n",
    "        pred_lst = [bnn.forward(data.x, mode='MC').data.numpy().squeeze(1) for _ in range(100)]\n",
    "        pred = np.array(pred_lst).T\n",
    "        pred_mean = pred.mean(axis=1)\n",
    "        pred_std = pred.std(axis=1)\n",
    "        \n",
    "        \n",
    "        if out == True:\n",
    "            if count == 0:\n",
    "                ids = [item for sublist in data.structure_id for item in sublist]\n",
    "                ids = [item for sublist in ids for item in sublist]\n",
    "                predict = output.data.cpu().numpy()\n",
    "                target = data.y.cpu().numpy()\n",
    "            else:\n",
    "                ids_temp = [\n",
    "                    item for sublist in data.structure_id for item in sublist\n",
    "                ]\n",
    "                ids_temp = [item for sublist in ids_temp for item in sublist]\n",
    "                ids = ids + ids_temp\n",
    "                predict = np.concatenate(\n",
    "                    (predict, output.data.cpu().numpy()), axis=0\n",
    "                )\n",
    "                target = np.concatenate((target, data.y.cpu().numpy()), axis=0)\n",
    "\n",
    "        count = count + output.size(0)\n",
    "\n",
    "loss_all = loss_all / count\n",
    "\n",
    "if out == True:\n",
    "    test_out = np.column_stack((ids, target, predict))\n",
    "    return loss_all, test_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current Model: Deep Evidential Regression\n",
    "\n",
    "Steps:\n",
    "1. Train regular model on data set \n",
    "2. Take the last layer from the model as the output as it outputs a 1-d vector\n",
    "3. Feed the vector into a gaussian regression model\n",
    "4. Output a mean and variance to create confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pprint\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from matdeeplearn import models, process, training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'config.yml'\n",
    "#os.path.exists(config_path)\n",
    "# os\n",
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(config_path), (\n",
    "    \"Config file not found in \" + config_path\n",
    "  )\n",
    "with open(config_path, \"r\") as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"Job\"] = config[\"Job\"]['Inductive_Conformal']\n",
    "config[\"Job\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"Processing\"][\"data_path\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"Models\"] = config[\"Models\"].get(\"MEGNet_demo\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Update config values from command line\n",
    "run_mode = config[\"Job\"].get(\"run_mode\")\n",
    "#config[\"Job\"] = config[\"Job\"].get('Training')\n",
    "print(config[\"Job\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "print(world_size)\n",
    "config[\"Processing\"][\"data_path\"] = \"data/pt_data/pt_data_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1,2'\n",
    "\n",
    "#torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = torch.cuda.device_count()\n",
    "print(world_size)\n",
    "config[\"Processing\"][\"data_path\"] = \"data/test_data/test_data_2\"\n",
    "training_parameters = config[\"Training\"]\n",
    "data_path = config[\"Processing\"][\"data_path\"]\n",
    "dataset = process.get_dataset(data_path, training_parameters[\"target_index\"], False, processing_args= config['Processing'])\n",
    "model_parameters = config[\"Models\"]\n",
    "job_parameters = config[\"Job\"]\n",
    "rank = \"cuda\"\n",
    "\n",
    "\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    train_sampler,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset,\n",
    ") = training.loader_setup(\n",
    "    training_parameters[\"train_ratio\"],\n",
    "    training_parameters[\"val_ratio\"],\n",
    "    training_parameters[\"test_ratio\"],\n",
    "    model_parameters[\"batch_size\"],\n",
    "    dataset,\n",
    "    rank,\n",
    "    job_parameters[\"seed\"],\n",
    "    world_size,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = training.model_setup(\n",
    "        rank,\n",
    "        model_parameters[\"model\"],\n",
    "        model_parameters,\n",
    "        dataset,\n",
    "        job_parameters[\"load_model\"],\n",
    "        job_parameters[\"model_path\"],\n",
    "        model_parameters.get(\"print_model\", True),\n",
    "    ) \n",
    "\n",
    "  ##Set-up optimizer & scheduler\n",
    "optimizer = getattr(torch.optim, model_parameters[\"optimizer\"])(\n",
    "    model.parameters(),\n",
    "    lr=model_parameters[\"lr\"],\n",
    "    **model_parameters[\"optimizer_args\"]\n",
    ")\n",
    "scheduler = getattr(torch.optim.lr_scheduler, model_parameters[\"scheduler\"])(\n",
    "    optimizer, **model_parameters[\"scheduler_args\"]\n",
    ")\n",
    "\n",
    "##Start training\n",
    "model = training.trainer(\n",
    "    rank,\n",
    "    world_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    training_parameters[\"loss\"],\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    train_sampler,\n",
    "    model_parameters[\"epochs\"],\n",
    "    training_parameters[\"verbosity\"],\n",
    "    \"my_model_temp.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error, train_out = training.evaluate(\n",
    "    train_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting a Frequency Distribution of Training Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_parameters = config['Job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_split = job_parameters[\"model_n\"].find('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ids = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    df = pd.read_csv(os.path.join(job_parameters[\"model_path\"],\n",
    "                         \"Bootstrap_Pred_\" + \n",
    "                         str(i) + '_train_outputs.csv'))\n",
    "    temp_ids = df['ids'].tolist()\n",
    "    my_ids = my_ids + temp_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ids = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    df = pd.read_csv(os.path.join(job_parameters[\"model_path\"],\n",
    "                         \"Bootstrap_Pred_\" + \n",
    "                         str(i) + '_train_outputs.csv'))\n",
    "    temp_ids = df['ids'].tolist()\n",
    "    my_ids = my_ids + temp_ids\n",
    "\n",
    "frame_dict = {'ids': np.unique(my_ids).tolist(), 'count': np.repeat(0,len(np.unique(my_ids).tolist()))}\n",
    "freq = pd.DataFrame(frame_dict)\n",
    "\n",
    "for item in my_ids: \n",
    "    if (item in freq['ids'].tolist()): \n",
    "        freq['count'][freq['ids'] == item] += 1\n",
    "    else: \n",
    "        print('oopsie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.iloc[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"bootstrap_freq_training_ids_check.csv\", \"w\") as f:\n",
    "\n",
    "    csvwriter = csv.writer(f)\n",
    "    for i in range(0,  len(my_ids)+1):\n",
    "        if i == 0:\n",
    "            csvwriter.writerow(\n",
    "                [\n",
    "                    \"ids\",\n",
    "                    'count'\n",
    "                ]\n",
    "            )\n",
    "        elif i > 0:\n",
    "            csvwriter.writerow(freq.iloc[i - 1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in my_ids: \n",
    "    if (item in freq['ids'].tolist()): \n",
    "        freq['count'][freq['ids'] == item] += 1\n",
    "    else: \n",
    "        print('oopsie')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"Job\"][\"parallel\"] = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"Processing\"][\"data_path\"] = 'data/pt_data/pt_data_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting Inductive Conformal Error training\")\n",
    "print(\n",
    "    \"running for \"\n",
    "    + str(config[\"Models\"][\"epochs\"])\n",
    "    + \" epochs\"\n",
    "    + \" on \"\n",
    "    + str(config[\"Job\"][\"model\"])\n",
    "    + \" model\" \n",
    "    )\n",
    "world_size = torch.cuda.device_count()\n",
    "if world_size == 0:\n",
    "    print(\"Running on CPU - this will be slow\")\n",
    "\n",
    "    training.train_ic_errors(\n",
    "        \"cpu\",\n",
    "        world_size,\n",
    "        config[\"Processing\"][\"data_path\"],\n",
    "        config[\"Job\"],\n",
    "        config[\"Training\"],\n",
    "        config[\"Models\"],\n",
    "        config['Processing']\n",
    "    )\n",
    "\n",
    "\n",
    "elif world_size > 0:\n",
    "    if config[\"Job\"][\"parallel\"] == \"True\":\n",
    "        print(\"Running on\", world_size, \"GPUs\")\n",
    "        mp.spawn(\n",
    "            training.train_ic_errors,\n",
    "            args=(\n",
    "                world_size,\n",
    "                config[\"Processing\"][\"data_path\"],\n",
    "                config[\"Job\"],\n",
    "                config[\"Training\"],\n",
    "                config[\"Models\"],\n",
    "                config['Processing'],\n",
    "            ),\n",
    "            nprocs=world_size,\n",
    "            join=True,\n",
    "        )\n",
    "    if config[\"Job\"][\"parallel\"] == \"False\":\n",
    "        print(\"Running on one GPU\")\n",
    "        training.train_ic_errors(\n",
    "            \"cuda\",\n",
    "            world_size,\n",
    "            config[\"Processing\"][\"data_path\"],\n",
    "            config[\"Job\"],\n",
    "            config[\"Training\"],\n",
    "            config[\"Models\"],\n",
    "            config['Processing']\n",
    "        )   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inductive Conformal (Hopefully this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,2\"\n",
    "import argparse\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pprint\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from matdeeplearn import models, process, training\n",
    "\n",
    "config_path = 'config.yml'\n",
    "#os.path.exists(config_path)\n",
    "# os\n",
    "os.path.abspath(os.getcwd())\n",
    "\n",
    "assert os.path.exists(config_path), (\n",
    "    \"Config file not found in \" + config_path\n",
    "  )\n",
    "with open(config_path, \"r\") as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "config[\"Job\"] = config[\"Job\"]['Inductive_Conformal']\n",
    "config[\"Models\"] = config[\"Models\"].get(\"MEGNet_demo\")\n",
    "world_size = torch.cuda.device_count()\n",
    "print(world_size)\n",
    "config[\"Processing\"][\"data_path\"] = \"data/pt_data/pt_data_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 'cuda'\n",
    "print(world_size)\n",
    "data_path = config[\"Processing\"][\"data_path\"]\n",
    "job_parameters= config[\"Job\"]\n",
    "training_parameters= config[\"Training\"]\n",
    "model_parameters= config[\"Models\"]\n",
    "processing_args= config['Processing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##General imports\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import copy\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import platform\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "##Torch imports\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader, Dataset\n",
    "from torch_geometric.nn import DataParallel\n",
    "import torch_geometric.transforms as T\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "##Matdeeplearn imports\n",
    "from matdeeplearn import models\n",
    "import matdeeplearn.process as process\n",
    "import matdeeplearn.training as training\n",
    "from matdeeplearn.models.utils import model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DDP\n",
    "training.ddp_setup(rank, world_size)\n",
    "##some issues with DDP learning rate\n",
    "if rank not in (\"cpu\", \"cuda\"):\n",
    "    model_parameters[\"lr\"] = model_parameters[\"lr\"] * world_size\n",
    "\n",
    "##Get dataset\n",
    "dataset = process.get_dataset(data_path, training_parameters[\"target_index\"], False)\n",
    "\n",
    "print('Done Processing')\n",
    "\n",
    "if rank not in (\"cpu\", \"cuda\"):\n",
    "    dist.barrier()\n",
    "\n",
    "##Set up loader\n",
    "(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    train_sampler,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset,\n",
    ") = training.loader_setup(\n",
    "    training_parameters[\"train_ratio\"],\n",
    "    training_parameters[\"val_ratio\"],\n",
    "    training_parameters[\"test_ratio\"],\n",
    "    model_parameters[\"batch_size\"],\n",
    "    dataset,\n",
    "    rank,\n",
    "    job_parameters[\"seed\"],\n",
    "    world_size,\n",
    ")\n",
    "\n",
    "##Set up model\n",
    "model =training.model_setup(\n",
    "    rank,\n",
    "    model_parameters[\"model\"],\n",
    "    model_parameters,\n",
    "    dataset,\n",
    "    job_parameters[\"load_model\"],\n",
    "    job_parameters[\"model_path\"],\n",
    "    model_parameters.get(\"print_model\", True),\n",
    ")\n",
    "\n",
    "##Set-up optimizer & scheduler\n",
    "optimizer = getattr(torch.optim, model_parameters[\"optimizer\"])(\n",
    "    model.parameters(),\n",
    "    lr=model_parameters[\"lr\"],\n",
    "    **model_parameters[\"optimizer_args\"]\n",
    ")\n",
    "scheduler = getattr(torch.optim.lr_scheduler, model_parameters[\"scheduler\"])(\n",
    "    optimizer, **model_parameters[\"scheduler_args\"]\n",
    ")\n",
    "\n",
    "##Start training\n",
    "model = training.trainer(\n",
    "    rank,\n",
    "    world_size,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    training_parameters[\"loss\"],\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    train_sampler,\n",
    "    model_parameters[\"epochs\"],\n",
    "    training_parameters[\"verbosity\"],\n",
    "    \"my_model_temp.pth\",\n",
    ")\n",
    "\n",
    "if rank in (0, \"cpu\", \"cuda\"):\n",
    "\n",
    "    train_error = val_error = test_error = float(\"NaN\")\n",
    "\n",
    "    ##workaround to get training output in DDP mode\n",
    "    ##outputs are slightly different, could be due to dropout or batchnorm?\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=model_parameters[\"batch_size\"],\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    test_loader = training.DataLoader(\n",
    "                    test_dataset,\n",
    "                    batch_size=model_parameters[\"batch_size\"],\n",
    "                    shuffle=False,\n",
    "                    num_workers=0,\n",
    "                    pin_memory=True,\n",
    "                )\n",
    "\n",
    "    val_loader = training.DataLoader(\n",
    "                    val_dataset,\n",
    "                    batch_size=model_parameters[\"batch_size\"],\n",
    "                    shuffle=False,\n",
    "                    num_workers=0,\n",
    "                    pin_memory=True,\n",
    "                )\n",
    "\n",
    "    ##Get train error in eval mode\n",
    "    train_error, train_out = training.evaluate(\n",
    "        train_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    "    )\n",
    "    print(\"Train Error: {:.5f}\".format(train_error))\n",
    "\n",
    "    ##Get val error\n",
    "    if val_loader != None:\n",
    "        val_error, val_out = training.evaluate(\n",
    "            val_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    "        )\n",
    "        print(\"Val Error: {:.5f}\".format(val_error))\n",
    "\n",
    "    ##Get test error\n",
    "    if test_loader != None:\n",
    "        test_error, test_out = training.evaluate(\n",
    "            test_loader, model, training_parameters[\"loss\"], rank, out=True\n",
    "        )\n",
    "        print(\"Test Error: {:.5f}\".format(test_error))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if job_parameters[\"save_model\"] == \"True\":\n",
    "\n",
    "    if rank not in (\"cpu\", \"cuda\"):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                \"full_model\": model,\n",
    "            },\n",
    "            job_parameters[\"model_path\"],\n",
    "        )\n",
    "    else:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                \"full_model\": model,\n",
    "            },\n",
    "            job_parameters[\"model_path\"],\n",
    "        )\n",
    "target_train = pd.DataFrame(train_out, columns=['index', 'target', 'predicted'])\n",
    "target_val = pd.DataFrame(val_out, columns=['index', 'target', 'predicted']) \n",
    "target_test = pd.DataFrame(test_out, columns=['index', 'target', 'predicted']) \n",
    "target_errors = pd.concat([target_train,target_val,target_test], axis = 0)\n",
    "target_errors = target_errors.sort_values(list(target_errors), ascending=True)\n",
    "target_errors['error'] = np.absolute(target_errors['target'].apply(float) - target_errors['predicted'].apply(float))\n",
    "target_errors[['index','error']].to_csv(os.path.join(os.getcwd(),data_path,'error_targets.csv'), index = False, header=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['train']*len(train_dataset.indices) + ['val']*len(val_dataset.indices) + ['test']*len(test_dataset.indices)\n",
    "my_indices = pd.DataFrame({'ind_type': names, 'inidex':train_dataset.indices+val_dataset.indices+test_dataset.indices})\n",
    "my_indices.to_csv(os.path.join(os.getcwd(),'data_indices_ic.csv'), index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = process.get_dataset_error(data_path ,training_parameters[\"target_index\"], False, processing_args)\n",
    "error_train_subset =  torch.utils.data.Subset(new_data, train_dataset.indices)\n",
    "error_val_subset = torch.utils.data.Subset(new_data, val_dataset.indices)\n",
    "error_test_subset = torch.utils.data.Subset(new_data, test_dataset.indices)\n",
    "\n",
    "train_loader_e = training.DataLoader(\n",
    "    error_train_subset,\n",
    "    batch_size=model_parameters[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader_e = training.DataLoader(\n",
    "                error_val_subset,\n",
    "                batch_size=model_parameters[\"batch_size\"],\n",
    "                shuffle=False,\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "            )\n",
    "\n",
    "test_loader_e = training.DataLoader(\n",
    "                error_test_subset,\n",
    "                batch_size=model_parameters[\"batch_size\"],\n",
    "                shuffle=False,\n",
    "                num_workers=0,\n",
    "                pin_memory=True,\n",
    "            )\n",
    "\n",
    "model_errors = training.model_setup(\n",
    "        rank,\n",
    "        model_parameters[\"model\"],\n",
    "        model_parameters,\n",
    "        new_data,\n",
    "        job_parameters[\"load_model\"],\n",
    "        job_parameters[\"model_path\"],\n",
    "        model_parameters.get(\"print_model\", True),\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = getattr(torch.optim, model_parameters[\"optimizer\"])(\n",
    "    model_errors.parameters(),\n",
    "    lr=model_parameters[\"lr\"],\n",
    "    **model_parameters[\"optimizer_args\"]\n",
    ")\n",
    "scheduler = getattr(torch.optim.lr_scheduler, model_parameters[\"scheduler\"])(\n",
    "    optimizer, **model_parameters[\"scheduler_args\"]\n",
    ")\n",
    "\n",
    "##Start training\n",
    "model_errors = training.trainer(\n",
    "    rank,\n",
    "    world_size,\n",
    "    model_errors,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    training_parameters[\"loss\"],\n",
    "    train_loader_e,\n",
    "    val_loader_e,\n",
    "    train_sampler,\n",
    "    model_parameters[\"epochs\"],\n",
    "    training_parameters[\"verbosity\"],\n",
    "    \"my_model_error_temp.pth\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error_e, train_out_e = training.evaluate(\n",
    "    train_loader_e, model_errors, training_parameters[\"loss\"], rank, out=True)\n",
    "\n",
    "val_error_e, val_out_e = training.evaluate(\n",
    "    val_loader_e, model_errors, training_parameters[\"loss\"], rank, out=True)\n",
    "\n",
    "test_error_e, test_out_e = training.evaluate(\n",
    "    test_loader_e, model_errors, training_parameters[\"loss\"], rank, out=True)\n",
    "\n",
    "\n",
    "target_train_e = pd.DataFrame(train_out_e, columns=['index', 'target_error', 'predicted_error'])\n",
    "target_val_e = pd.DataFrame(val_out_e, columns=['index', 'target_error', 'predicted_error']) \n",
    "target_test_e = pd.DataFrame(test_out_e, columns=['index', 'target_error', 'predicted_error']) \n",
    "target_errors_e = pd.concat([target_train_e,target_val_e,target_test_e], axis = 0)\n",
    "target_errors_e = target_errors_e.sort_values(list(target_errors_e), ascending=True)\n",
    "target_errors_e['error_2'] = np.absolute(target_errors_e['target_error'].apply(float) - target_errors_e['predicted_error'].apply(float))\n",
    "\n",
    "target_val_e_2 = copy.copy(target_val_e)\n",
    "target_val_e_2['target_error'] = target_val_e_2['target_error'].apply(float)\n",
    "target_val_e_2['predicted_error'] = target_val_e_2['predicted_error'].apply(float)\n",
    "target_val_e_2['alpha'] = target_val_e_2['target_error']/target_val_e_2['predicted_error']\n",
    "\n",
    "target_val_e_2 = target_val_e_2.sort_values(['alpha'], axis=0, ascending=True)\n",
    "alpha = np.percentile(target_val_e_2['alpha'], 95)\n",
    "\n",
    "target_train_e['predicted_error'] = target_train_e['predicted_error'].apply(float)\n",
    "target_train_e['lower_error_confidence_level'] = target_train_e['predicted_error'] - alpha\n",
    "target_train_e['upper_error_confidence_level'] = target_train_e['predicted_error'] + alpha\n",
    "\n",
    "target_val_e['predicted_error'] = target_val_e['predicted_error'].apply(float)\n",
    "target_val_e['lower_error_confidence_level'] = target_val_e['predicted_error'] - alpha\n",
    "target_val_e['upper_error_confidence_level'] = target_val_e['predicted_error'] + alpha\n",
    "\n",
    "target_test_e['predicted_error'] = target_test_e['predicted_error'].apply(float)\n",
    "target_test_e['lower_error_confidence_level'] = target_test_e['predicted_error'] - alpha\n",
    "target_test_e['upper_error_confidence_level'] = target_test_e['predicted_error'] + alpha\n",
    "\n",
    "\n",
    "target_train_e.to_csv(os.path.join(os.getcwd(),'error_prediction_conf_train.csv'), index = False, header=False)\n",
    "target_val_e.to_csv(os.path.join(os.getcwd(),'error_prediction_conf_val.csv'), index = False, header=False)\n",
    "target_test_e.to_csv(os.path.join(os.getcwd(),'error_prediction_conf_test.csv'), index = False, header=False)\n",
    "\n",
    "        ##Write outputs\n",
    "if job_parameters[\"write_output\"] == \"True\":\n",
    "\n",
    "    training.write_results(\n",
    "        train_out, str(job_parameters[\"job_name\"]) + \"_train_outputs.csv\"\n",
    "    )\n",
    "    if val_loader != None:\n",
    "        training.write_results(\n",
    "            val_out, str(job_parameters[\"job_name\"]) + \"_val_outputs.csv\"\n",
    "        )\n",
    "    if test_loader != None:\n",
    "        training.write_results(\n",
    "            test_out, str(job_parameters[\"job_name\"]) + \"_test_outputs.csv\"\n",
    "        )\n",
    "\n",
    "if rank not in (\"cpu\", \"cuda\"):\n",
    "    dist.destroy_process_group()\n",
    "\n",
    "##Write out model performance to file\n",
    "error_values = np.array((train_error.cpu(), val_error.cpu(), test_error.cpu()))\n",
    "if job_parameters.get(\"write_error\") == \"True\":\n",
    "    np.savetxt(\n",
    "        job_parameters[\"job_name\"] + \"_errorvalues.csv\",\n",
    "        error_values[np.newaxis, ...],\n",
    "        delimiter=\",\",\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "old_Cuda",
   "language": "python",
   "name": "old_cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
